"""
ê²€ìƒ‰ í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸ ì œê³µ í•¨ìˆ˜
"""
from app.backend.core.logger import get_logger
from app.backend.data.db_util import search_law_summary, get_site_and_code_dict

logger = get_logger(__name__)


def get_sites_list():
    """
    ì‚¬ì´íŠ¸ ëª©ë¡ ë°˜í™˜ (ë“œë¡­ë‹¤ìš´ìš©)

    Returns:
        [{"code": "code1", "name": "ì‚¬ì´íŠ¸ëª…1"}, ...]
    """
    try:
        site_dict = get_site_and_code_dict()
        sites = [
            {"code": code, "name": name}
            for code, name in site_dict.items()
        ]
        return sorted(sites, key=lambda x: x["name"])
    except Exception as e:
        logger.error(f"âŒ ì‚¬ì´íŠ¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


def search_data(site_names: list = None, keyword: str = "", page: int = 1, pagesize: int = 30):
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ ë°ì´í„° ê²€ìƒ‰ (í˜ì´ì§• ì§€ì›)

    Args:
        site_names: ì„ íƒëœ ì‚¬ì´íŠ¸ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒì‚¬í•­)
        page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
        pagesize: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜

    Returns:
        {
            "items": ê²€ìƒ‰ ê²°ê³¼,
            "total": ì „ì²´ í•­ëª© ìˆ˜,
            "page": í˜„ì¬ í˜ì´ì§€,
            "pagesize": í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜,
            "total_pages": ì „ì²´ í˜ì´ì§€ ìˆ˜
        }
    """
    try:
        # site_namesê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ì „ì²´ ì¡°íšŒ)
        if site_names is None or len(site_names) == 0:
            site_names = []

        # í‚¤ì›Œë“œê°€ ì—†ê³  ì‚¬ì´íŠ¸ë„ ì„ íƒë˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if not keyword.strip() and len(site_names) == 0:
            return {
                "items": [],
                "total": 0,
                "page": page,
                "pagesize": pagesize,
                "total_pages": 0
            }

        df = search_law_summary(site_names=site_names, keyword=keyword)

        # ì „ì²´ í•­ëª© ìˆ˜ ê³„ì‚°
        total_count = len(df)
        total_pages = (total_count + pagesize - 1) // pagesize

        # í˜ì´ì§€ë³„ ë°ì´í„° ìŠ¬ë¼ì´ì‹±
        start_idx = (page - 1) * pagesize
        end_idx = start_idx + pagesize
        paginated_df = df.iloc[start_idx:end_idx]

        # í˜ì´ì§• ì •ë³´ ë¡œê¹…
        logger.info(f"ğŸ“„ í˜ì´ì§•: {page}/{total_pages} (ì „ì²´: {total_count}ê±´, í˜ì´ì§€ë‹¹: {pagesize}ê±´, í˜„ì¬í˜ì´ì§€: {len(paginated_df)}ê±´)")

        # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        rows = []
        for _, row in paginated_df.iterrows():
            rows.append({
                "site_name": row.get("ì‚¬ì´íŠ¸", ""),
                "page_id": row.get("í˜ì´ì§€", ""),
                "title": row.get("ì œëª©", ""),
                "registration_date": row.get("ë“±ë¡ì¼", ""),
                "collection_date": row.get("ìˆ˜ì§‘ì¼ì‹œ", ""),
                "site_url": row.get("site_url", ""),
                "detail_url": row.get("detail_url", ""),
                "org_url": row.get("org_url", ""),
                "summary": row.get("summary", ""),
                "attachment_count": 0,
                "attachments": []
            })

        return {
            "items": rows,
            "total": total_count,
            "page": page,
            "pagesize": pagesize,
            "total_pages": total_pages
        }
    except Exception as e:
        logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {
            "items": [],
            "total": 0,
            "page": page,
            "pagesize": pagesize,
            "total_pages": 0
        }
